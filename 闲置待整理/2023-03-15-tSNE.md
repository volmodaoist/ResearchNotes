### t-SNE 降维方法

PCA 主成分分析方法是降维领域的最常用算法，这是一种线性降维算法，计算速度较快，但它无法维护数据集的局部结构，为此使用 t-SNE 算法捕获高维数据的复杂流行结构，解决局部结构的问题，相较于PCA算法，t-SNE (t-Distributed Stochastic Neighbor Embedding) 算法的优势主要有以下几点：

- 保留数据的局部结构；
- 可视化效果较好；

为了更好将数据投影至低维空间中，算法尝试去最小化高维数据空间和低维数据空间之间的条件概率之差，具体来说，会使用梯度下降的方法最小化原分布中数据与映射分布中的对应数据之间的 KL 散度，因而缺点在于：

- 运算量较大，耗时更多；
- 运行结果不稳定；



**首先介绍一般 SNE 实现步骤详见下文：**

1. 计算相似度矩阵：首先需要计算原始数据集中所有点两两之间的相似度，时间复杂度下界 $O(n^2)$，而后 t-SNE 职中，通常使用高斯分布来度量相似度，即对于数据点 $x_i$ 和 $x_j$，它们在高维空间中的距离可以表示下式，其中 $\sigma_i$ 是一个自适应的参数，用来控制高斯分布的方差，一般取为 $p_{j|i}$ 某分位数。
   $$
   p_{j|i} = \cfrac{\exp(-\cfrac{\Vert{x_i - x_j}\Vert^2}{2\sigma_i^2})}{\sum_{k \neq i} \exp(-\cfrac{\Vert{x_i - x_k}\Vert^2}{2\sigma_i^2})}
   $$
   
2. 计算低维空间中的相似度矩阵：对于低维空间中的每对点 $y_i$ 和 $y_j$，计算它们之间的相似度 $q_{j|i}$。通常使用 t 分布来度量相似度，也即：

$$
q_{j|i} = \cfrac{\exp(-\Vert y_i - y_j \Vert^2)}{\sum_{k\neq i}\exp{(-\Vert y_i - y_k \Vert^2)}}
$$



3. 最小化 KL 散度：t-SNE 通过最小化 KL 散度来优化低维空间中的点的位置，使得相似的点在低维空间中距离更近，不相似的点距离更远。KL 散度可以定义为：
   $$
   C =\sum_{i}\text{KL}(P_i \Vert Q_i) = \sum_i\sum_j p_{j|i}\log\cfrac{p_{j|i}}{q_{j|i}}
   $$

**如何改进得到 t-SNE 算法: **

其优化算法采用随机梯度下降法（SGD）来最小化 KL 散度，通过不断更新低维空间中每个点的位置来达到这个目的。最终，算法将高维数据映射到一个二维或三维空间中，从而可以将数据可视化出来。不过 KL 散度的不对称性会导致算法只关注数据局部结构，忽略数据的全部结构。为此，要将高维空间之中的联合概率改为 $p_{ij} = \frac{p_{i|j}+p_{j|i}}{2}$，然后使用 t 分布代替高斯分布，因为 t 分布的尾部较高，对异常点不敏感，保证了其鲁棒性，因此其拟合结果更为合理，较好的捕获了数据的整体特征，至此也就得到了 **t-SNE**



> 更多降维方法参考知乎 [「六种常用数据降维方法」](https://zhuanlan.zhihu.com/p/159285110)，t-SNE 算法的数学原理来自[这里](https://blog.csdn.net/sinat_20177327/article/details/80298645)