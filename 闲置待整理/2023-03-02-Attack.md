### NN 有趣性质

- 文章指出了神经网络的两个性质：
  - 语义信息是在整个特征空间之中的，而非单个神经元
  - 通过添加难以察觉的微小的扰动能令模型产生巨大的偏差；对抗样本
    - 对抗样本能够跨模型 (模型结构相似本超参数、层数不同)
    - 对抗样本能够跨数据集 (同一个数据集的不相交子集)

- **阅读论文「Intriguing properties of neural networks」遇到的概念**
  - 箱体约束问题，每个变量都约束在一定范围之内，L-BFGS 方法
    - **A box-constrained optimization problem** is a type of mathematical problem where you want to find the minimum or maximum value of a function s**ubject to some constraints on the variables**. The constraints are that each variable must **lie within a certain range**, **called a box**. For example, if you want to optimize the volume of a box with a fixed girth, you have to choose its width and length within some limits
  - 大部分神经网络是非凸函数，意味着存在大量局部最值，难以达到全局最优
    - **Neural networks are non-convex in general**. This means that their cost function has multiple local minima and maxima, and finding the global optimum is hard. However, some special cases of neural networks may be convex, such as single-layer networks with linear activation functions.



下面是来自文章的截图，文章使用**自然基向量、随机向量**分别测试模型末层的特征，因为过去的一些研究认为模型末层的向量，每个维度都是具有明确的语义信息，所以通过检查这个**特征向量的每个维度**即可 (individual corrdinates of the feature spaces) 

![image-20230302161132171](./images/image-20230302161132171.png)

然而作用惊讶的发现，使用自然基向量 (Natural basis direction)、随机向量 (Random basis)  来求激活值最大图片，得出来的结果竟然是相似的，其获得的一组最大激活单元具有相似的语义信息。





- 作者想到了使用对抗训练的方法提高模型的鲁棒性
  - The network was trained in an alternating fashion, **maintaining and updating a pool of adversarial examples for each layer separately in addition to the original training set.** According to our initial observations, adversarial examples **for the higher layers seemed to be significantly more useful** than those on the input or lower layers.
  - We have successfully trained a two layer 100-100-10 non-convolutional neural network with a test error below 1.2% **by keeping a pool of adversarial examples**, a random subset of **which is continuously replaced by newly generated adversarial examples** and which is mixed into the original training set all the time.

为每一层分别维护和更新一个对抗样本池，使用每一层的输出结果生成新对抗样本，再拿这些样本更新对抗样本池的一个随机自己；

> 看到这里有一些疑问❓
>
> - 不同 layer 生成的特征图尺寸是不一样，如何拿来作为模型输入参与训练？莫非模型通过填充使得每一层的特征图尺寸一样吗？
> - 这篇论文提出的时候没有对抗攻击的算法，那么作者是如何生成对抗样本的？
> - 文章的 Experimental results 主要是通过实验说明为什么对抗样本能够跨模型、跨数据集，不过这篇文章的不稳定性谱分析主要是在做什么呢？





这篇文章是对抗攻击开篇之作：Intriguing properties of neural networks，之后出现了两类经典的攻击算法

- FGSM 算法：Explaining and Harnessing Adversarial Examples

- PGD 算法：Towards Deep Learning Models Resistant to Adversarial Attacks